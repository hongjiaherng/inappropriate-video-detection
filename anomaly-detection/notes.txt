- model
- loss
- dataset
- optimizer with LR scheduler
- train
- test
- infer



Dataset preprocessing

train
for each video:
- all clip features of a video ->
- if more than threshold (200), uniformly sample 200 clips features, otherwise, take all but zero pad to 200 ->
- generate video-level label, 0 or 1

test
for each video:
- take whole video don't care about number of clips
- generate ground truth label


- say options first

- dataset whether streaming or not
    - should always shuffle train Dataset, apply a preprocessing to input
    - should not shuffle test Dataset and batch size of 5 to load all crops of a video at once, apply a preprocessing to target

- What i wanna log?
    - train:
        - train loss (including 2 MILLoss & 1 DistillLoss) per step
        - train loss (including 2 MILLoss & 1 DistillLoss) per epoch
    - test:
        - test loss (including 2 MILLoss & 1 DistillLoss) per epoch
        - test metrics per epoch

- How i wanna use it?

- config?
    - cli args config should not have default value, it must override the config file if specified


# TODO: Add console logger
# TODO: Add wandb logger for metrics, model checkpoints, configs
# Use wandb to:
# - Log metrics
#   - Train loss (total, distill, mil_hl, mil_hlc) (every epoch or every n steps)
#   - Test loss (total, distill, mil_hl, mil_hlc) (every epoch)
#   - Test metrics (every epoch)
#       - PRC-AUC (score vs epoch, accumulate)
#       - ROC-AUC (score vs epoch, accumulate)
#       - PRC (renew every epoch)
#           - Plot in the same graph
#       - ROC (renew every epoch)
# - Save model checkpoints
# - Save configs